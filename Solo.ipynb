{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b47ad8ea-8b81-4673-9898-ee1676859c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# desabilitar avisos\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ccd20e-5ac5-4da4-a766-0f84655783f1",
   "metadata": {},
   "source": [
    "# 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5196a4c-18fc-4860-bda2-b813ae8efb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'SOLO' # será usado para salvar o arquivo processado\n",
    "df = pd.read_excel('Data/' + file_name + '.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5ce9581-0a9e-476b-ad7d-475fd5a1336a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROJETO_AMOSTRAGEM', 'PROJETO_PUBLICACAO', 'CENTRO_DE_CUSTO', 'CLASSE', 'NUMERO_DE_CAMPO', 'NUMERO_DE_LABORATORIO', 'DUPLICATA', 'LATITUDE', 'LONGITUDE', 'LOTE', 'RA', 'DATA_DE_ANALISE', 'METODO', 'ABERTURA', 'LEITURA', 'LABORATORIO', 'JOB', 'Ag_ppb', 'Ag_ppm', 'Al_pct', 'Al2O3_pct', 'As_ppm', 'Au_ppb', 'Au_ppm', 'B_ppm', 'Ba_ppm', 'BaO_pct', 'Be_ppm', 'Bi_ppm', 'C_organico_pct', 'C_elementar_pct', 'Ca_pct', 'CaO_pct', 'Cd_ppm', 'Ce_ppm', 'Cl_ppm', 'Co_ppm', 'CO3_pct', 'Cr_pct', 'Cr_ppm', 'Cr2O3_pct', 'Cs_ppm', 'Cu_ppm', 'Dy_ppm', 'Er_ppm', 'Eu_ppm', 'F_ppm', 'Fe_pct', 'Fe_ppm', 'Fe2O3_pct', 'FeO_pct', 'Ga_ppm', 'Gd_ppm', 'Ge_ppm', 'Hf_ppm', 'Hg_ppb', 'Hg_ppm', 'Ho_ppm', 'In_ppm', 'K_pct', 'K2O_pct', 'La_ppm', 'Li_ppm', 'Lu_ppm', 'Mg_pct', 'MgO_pct', 'Mn_pct', 'Mn_ppm', 'MnO_pct', 'Mo_ppm', 'Na_pct', 'Na2O_pct', 'Nb_ppm', 'Nb2O5_pct', 'Nd_ppm', 'Ni_pct', 'Ni_ppm', 'P_pct', 'P_ppm', 'P2O5_pct', 'Pb_ppb', 'Pb_ppm', 'Pd_ppb', 'Pd_ppm', 'PF_pct', 'Pr_ppm', 'Pt_ppb', 'Pt_ppm', 'Rb_ppm', 'Re_ppb', 'Re_ppm', 'Rh_ppb', 'S_pct', 'Sb_ppm', 'Sc_ppm', 'Se_ppm', 'SiO2_pct', 'Sm_ppm', 'Sn_ppm', 'Sr_ppm', 'Soma_pct', 'Ta_ppm', 'Tb_ppm', 'Te_ppm', 'Th_ppm', 'Ti_pct', 'Ti_ppm', 'TiO2_pct', 'Tl_ppm', 'Tm_ppm', 'U_ppm', 'V_ppm', 'W_ppm', 'Y_ppm', 'Yb_ppm', 'Zn_ppm', 'Zn_pct', 'Zr_ppm', 'OBSERVACAO']\n"
     ]
    }
   ],
   "source": [
    "# Show all collumns\n",
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ba465d-9327-4b9b-88d9-7c8c276aa6dd",
   "metadata": {},
   "source": [
    "# 2. Organizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10da52a-bc25-4996-bac9-54bb8d706376",
   "metadata": {},
   "source": [
    "## 2.1. ID columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf18852-5dd8-481a-b694-25ccb3f64ee5",
   "metadata": {},
   "source": [
    "As colunas `ID_AMOSTRA` e `ID_REGISTRO` são colocadas após a coluna `JOB`. Encontre o índice da coluna `JOB` e adicione 1 e 2, respectivamente. <br>\n",
    "<font color='gray'>The `ID_AMOSTRA` and `ID_REGISTRO` columns are placed after the `JOB` column. Find the index of the `JOB` column and add 1 and 2, respectively.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80d43c44-5fc7-4c0e-a511-e19f4d1fa1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reference position\n",
    "base_pos = df.columns.get_loc('JOB')\n",
    "\n",
    "# Insert ID_AMOSTRA at JOB + 1\n",
    "df.insert(base_pos + 1, 'ID_AMOSTRA', df['NUMERO_DE_CAMPO'])\n",
    "\n",
    "# Insert ID_REGISTRO at JOB + 2\n",
    "df.insert(base_pos + 1, 'ID_REGISTRO', df['NUMERO_DE_CAMPO'] + '_' + df['METODO'] + '_' + df['JOB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff9c4d-7952-4416-976a-875f83d1936a",
   "metadata": {},
   "source": [
    "## 2.2. Remove duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609ffe94-0b8a-40b9-8eaa-3738ba1c2638",
   "metadata": {},
   "source": [
    "### Filtering by DUPLICATA column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d857c05b-1d6f-4147-8bb4-a98fdbcc8e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Sim'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DUPLICATA'].unique() #Verificar como são classificadas as duplicatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80747c7a-3727-406c-8274-0ef384afc0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra somente os dados que a 'DUPLICATA' não é 'Sim'\n",
    "# Filtering the dataframe to keep only rows where 'DUPLICATA' is not 'Sim'\n",
    "df_duplicata = df[(df['DUPLICATA'] == 'Sim')]\n",
    "df = df[~(df['DUPLICATA'] == 'Sim')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff386a7-24a3-459a-8010-ce2bbb0105aa",
   "metadata": {},
   "source": [
    "### Filterin by duplicate ID_AMOSTRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e499ae-35b5-43f3-adbf-877e61b47161",
   "metadata": {},
   "source": [
    "Os dados contém análises de diferentes métodos (`ABERTURA`) em uma mesma amostra, assim desses dados defem ser juntados em uma mesma linha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedf085a-6911-4c61-a31e-15ac1d9e42a6",
   "metadata": {},
   "source": [
    "A função `combinar` vará a limpeza das linhas<br>\n",
    "<font color='red'> A função `combinar` leva cerca de 20 segundo para arrumar 1000 linhas</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86bf617b-1629-43bc-ab19-08f1f57dc75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinar(coluna):\n",
    "    # Remove valores ausentes (NaN) gerados por células vazias ou leituras inexistentes\n",
    "    valores = coluna.dropna()\n",
    "    \n",
    "    # Remove valores que são strings vazias, evitando considerar \"\" como dado válido\n",
    "    valores = valores[valores.astype(str).str.strip() != \"\"]\n",
    "    \n",
    "    # Retorna o primeiro valor válido encontrado na amostra;\n",
    "    # se não houver nenhum valor preenchido, retorna string vazia\n",
    "    return valores.iloc[0] if not valores.empty else \"\"\n",
    "\n",
    "df_raw = df.copy() # copia do df original para ser comparado depois\n",
    "\n",
    "df = (\n",
    "    # Agrupa os dados por número de campo, reunindo linhas da mesma amostra\n",
    "    df.groupby(\"NUMERO_DE_CAMPO\", as_index=False)\n",
    "      # Para cada coluna, aplica a função que seleciona o valor efetivamente medido\n",
    "      .agg(combinar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8b63658-6fb7-4294-a537-9a7668681934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMERO_DE_CAMPO</th>\n",
       "      <th>Cu_ppm</th>\n",
       "      <th>Dy_ppm</th>\n",
       "      <th>Er_ppm</th>\n",
       "      <th>Eu_ppm</th>\n",
       "      <th>F_ppm</th>\n",
       "      <th>Fe_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2251-HA-L-A001</td>\n",
       "      <td>21</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;50</td>\n",
       "      <td>1,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2251-HA-L-A002</td>\n",
       "      <td>35</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;50</td>\n",
       "      <td>2,7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NUMERO_DE_CAMPO Cu_ppm Dy_ppm Er_ppm Eu_ppm F_ppm Fe_pct\n",
       "1  2251-HA-L-A001     21                        <50    1,9\n",
       "2  2251-HA-L-A002     35                        <50    2,7"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dados filtrados\n",
    "\n",
    "df.loc[\n",
    "    df[\"NUMERO_DE_CAMPO\"].isin([\"2251-HA-L-A001\", \"2251-HA-L-A002\"]),\n",
    "    [\"NUMERO_DE_CAMPO\", \"Cu_ppm\", \"Dy_ppm\", \"Er_ppm\", \"Eu_ppm\", \"F_ppm\", \"Fe_pct\"]\n",
    "].sort_values(\"NUMERO_DE_CAMPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b01e7b5-0f81-4695-9dc2-bb2a4098ed10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMERO_DE_CAMPO</th>\n",
       "      <th>Cu_ppm</th>\n",
       "      <th>Dy_ppm</th>\n",
       "      <th>Er_ppm</th>\n",
       "      <th>Eu_ppm</th>\n",
       "      <th>F_ppm</th>\n",
       "      <th>Fe_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2251-HA-L-A001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>2251-HA-L-A001</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>2251-HA-L-A002</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>2251-HA-L-A002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    NUMERO_DE_CAMPO Cu_ppm  Dy_ppm  Er_ppm  Eu_ppm F_ppm Fe_pct\n",
       "33   2251-HA-L-A001    NaN     NaN     NaN     NaN   <50    NaN\n",
       "664  2251-HA-L-A001     21     NaN     NaN     NaN   NaN    1,9\n",
       "348  2251-HA-L-A002     35     NaN     NaN     NaN   NaN    2,7\n",
       "665  2251-HA-L-A002    NaN     NaN     NaN     NaN   <50    NaN"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dados originais\n",
    "\n",
    "df_raw.loc[\n",
    "    df_raw[\"NUMERO_DE_CAMPO\"].isin([\"2251-HA-L-A001\", \"2251-HA-L-A002\"]),\n",
    "    [\"NUMERO_DE_CAMPO\", \"Cu_ppm\", \"Dy_ppm\", \"Er_ppm\", \"Eu_ppm\", \"F_ppm\", \"Fe_pct\"]\n",
    "].sort_values(\"NUMERO_DE_CAMPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad98615a-e5a9-446c-9a48-80959bf54553",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: No duplicate ID_AMOSTRA found.\n"
     ]
    }
   ],
   "source": [
    "# Identify rows with duplicate ID_AMOSTRA\n",
    "duplicates_count = df['ID_AMOSTRA'].duplicated().sum()\n",
    "\n",
    "if duplicates_count > 0:\n",
    "    print(f'Warning: {duplicates_count} duplicate IDs found!')\n",
    "    # Show the duplicated rows for inspection\n",
    "    df_duplicates = df[df['ID_AMOSTRA'].duplicated(keep=False)]\n",
    "    print(df_duplicates.sort_values(by='ID_AMOSTRA'))\n",
    "else:\n",
    "    print('Success: No duplicate ID_AMOSTRA found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7a18de-3149-48ab-a14a-6e06e5d3cadb",
   "metadata": {},
   "source": [
    "# 3. Limit of detection (LOD), NA and zero values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e888f-7bfb-45a8-a98e-eafe5c22ef03",
   "metadata": {},
   "source": [
    "## 3.1. Filtering data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c6444-4f09-4911-aa6b-b7c5d49943e4",
   "metadata": {},
   "source": [
    "Identifica e quantifica a presença de valores relacionados a Limites de Detecção (LOD), zeros e nulos. Os resultados são divididos em duas saídas: uma lista de colunas totalmente vazias e uma tabela mostrando a porcentagem de valores 'não ideais' por elemento <br>\n",
    "<font color='gray'>Identify and quantify the presence of values related to Limits of Detection (LOD), zeros, and nulls. The results are split into two outputs: a list of entirely empty columns and a table showing the percentage of 'non-ideal' values per element.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4873558-71b5-434d-aaca-039561469595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EMPTY COLUMNS | COLUNAS VAZIAS ---\n",
      "['Ag_ppb', 'Al2O3_pct', 'Au_ppb', 'BaO_pct', 'C_organico_pct', 'C_elementar_pct', 'CaO_pct', 'Cl_ppm', 'CO3_pct', 'Cr_pct', 'Cr2O3_pct', 'Dy_ppm', 'Er_ppm', 'Eu_ppm', 'Fe_ppm', 'Fe2O3_pct', 'FeO_pct', 'Gd_ppm', 'Hg_ppb', 'Ho_ppm', 'K2O_pct', 'MgO_pct', 'Mn_pct', 'MnO_pct', 'Na2O_pct', 'Nb2O5_pct', 'Nd_ppm', 'Ni_pct', 'P_pct', 'P2O5_pct', 'Pb_ppb', 'Pd_ppb', 'Pd_ppm', 'PF_pct', 'Pr_ppm', 'Pt_ppb', 'Pt_ppm', 'Re_ppb', 'Rh_ppb', 'SiO2_pct', 'Sm_ppm', 'Soma_pct', 'Ti_ppm', 'TiO2_pct', 'Tm_ppm', 'Zn_pct']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.replace('', np.nan) # substitui string vazio por nan\n",
    "df = df.replace('ND', np.nan) # substitui ND por nan\n",
    "\n",
    "# Identificar colunas numéricas (elementos) e colunas totalmente vazias\n",
    "# Identify empty columns\n",
    "cols_elementos = [col for col in df.columns if '_' in col]\n",
    "colunas_vazias = [col for col in cols_elementos if df[col].isnull().all()]\n",
    "colunas_com_dados = [col for col in cols_elementos if col not in colunas_vazias]\n",
    "\n",
    "# Saída 1: Lista de colunas vazias\n",
    "print('--- EMPTY COLUMNS | COLUNAS VAZIAS ---')\n",
    "if colunas_vazias:\n",
    "    print(colunas_vazias)\n",
    "else:\n",
    "    print('No entirely empty columns found.')\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d2924cd-82d5-408d-9de3-a98f730da62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 46 empty columns.\n"
     ]
    }
   ],
   "source": [
    "# Remover colunas vazias\n",
    "# Remove empty columns\n",
    "\n",
    "df.drop(columns=colunas_vazias, inplace=True)\n",
    "\n",
    "print(f'Removed {len(colunas_vazias)} empty columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e8ca168-def5-458b-8a97-9eed8296f1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LOD & NULL SUMMARY (%) | RESUMO DE LOD E NULOS (%) ---\n",
      "       LOD/Null %\n",
      "Ag_ppm     99.75%\n",
      "Al_pct     99.75%\n",
      "As_ppm     99.75%\n",
      "Au_ppm    100.00%\n",
      "B_ppm      97.53%\n",
      "Ba_ppm     97.28%\n",
      "Be_ppm     97.53%\n",
      "Bi_ppm     99.75%\n",
      "Ca_pct     97.53%\n",
      "Cd_ppm    100.00%\n",
      "Ce_ppm     99.75%\n",
      "Co_ppm     97.28%\n",
      "Cr_ppm     97.28%\n",
      "Cs_ppm     99.75%\n",
      "F_ppm     100.00%\n",
      "Ga_ppm     99.75%\n",
      "Ge_ppm    100.00%\n",
      "Hf_ppm     99.75%\n",
      "Hg_ppm     99.75%\n",
      "In_ppm     99.75%\n",
      "K_pct      99.75%\n",
      "La_ppm     97.53%\n",
      "Li_ppm    100.00%\n",
      "Lu_ppm    100.00%\n",
      "Mg_pct     97.28%\n",
      "Mo_ppm     99.75%\n",
      "Na_pct     99.75%\n",
      "Nb_ppm     98.77%\n",
      "Ni_ppm     97.28%\n",
      "P_ppm      86.91%\n",
      "Pb_ppm      0.99%\n",
      "Rb_ppm     99.75%\n",
      "Re_ppm    100.00%\n",
      "S_pct     100.00%\n",
      "Sb_ppm     99.75%\n",
      "Sc_ppm     97.28%\n",
      "Se_ppm    100.00%\n",
      "Sn_ppm     99.75%\n",
      "Sr_ppm     99.75%\n",
      "Ta_ppm    100.00%\n",
      "Tb_ppm    100.00%\n",
      "Te_ppm     99.75%\n",
      "Th_ppm     99.75%\n",
      "Ti_pct     97.78%\n",
      "Tl_ppm    100.00%\n",
      "U_ppm      99.75%\n",
      "V_ppm      97.28%\n",
      "W_ppm      99.75%\n",
      "Y_ppm      97.28%\n",
      "Yb_ppm    100.00%\n",
      "Zn_ppm      1.98%\n",
      "Zr_ppm     97.28%\n"
     ]
    }
   ],
   "source": [
    "# Função para identificar o que é 'LOD' ou dado problemático\n",
    "# Identify LOD value\n",
    "def contar_lod(series):\n",
    "    # Converte para string para buscar símbolos, mas mantém análise de nulos/zeros\n",
    "    total = len(series)\n",
    "    # Contagem de nulos, zeros e strings com < ou >\n",
    "    mascara_lod = (series.astype(str).str.contains('<|>') | (series == 0) | series.isna())\n",
    "    \n",
    "    soma = mascara_lod.sum()\n",
    "    return (soma / total) * 100 if soma > 0 else 0\n",
    "\n",
    "# Gerar resultados\n",
    "resultados = {}\n",
    "for col in colunas_com_dados:\n",
    "    porcentagem = contar_lod(df[col])\n",
    "    if porcentagem > 0:\n",
    "        resultados[col] = f'{porcentagem:.2f}%'\n",
    "\n",
    "print('--- LOD & NULL SUMMARY (%) | RESUMO DE LOD E NULOS (%) ---')\n",
    "if resultados:\n",
    "    df_resumo = pd.DataFrame.from_dict(resultados, orient='index', columns=['LOD/Null %'])\n",
    "    print(df_resumo)\n",
    "else:\n",
    "    print('No LOD or null values detected in data-containing columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f412cd2-a2b2-44d8-a659-9bb947323708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- REMOVAL SUMMARY | RESUMO DE REMOÇÃO ---\n",
      "Removed 50 columns with >30% LOD/Nulls:\n",
      "Ag_ppm: 99.75%\n",
      "Al_pct: 99.75%\n",
      "As_ppm: 99.75%\n",
      "Au_ppm: 100.00%\n",
      "B_ppm: 97.53%\n",
      "Ba_ppm: 97.28%\n",
      "Be_ppm: 97.53%\n",
      "Bi_ppm: 99.75%\n",
      "Ca_pct: 97.53%\n",
      "Cd_ppm: 100.00%\n",
      "Ce_ppm: 99.75%\n",
      "Co_ppm: 97.28%\n",
      "Cr_ppm: 97.28%\n",
      "Cs_ppm: 99.75%\n",
      "F_ppm: 100.00%\n",
      "Ga_ppm: 99.75%\n",
      "Ge_ppm: 100.00%\n",
      "Hf_ppm: 99.75%\n",
      "Hg_ppm: 99.75%\n",
      "In_ppm: 99.75%\n",
      "K_pct: 99.75%\n",
      "La_ppm: 97.53%\n",
      "Li_ppm: 100.00%\n",
      "Lu_ppm: 100.00%\n",
      "Mg_pct: 97.28%\n",
      "Mo_ppm: 99.75%\n",
      "Na_pct: 99.75%\n",
      "Nb_ppm: 98.77%\n",
      "Ni_ppm: 97.28%\n",
      "P_ppm: 86.91%\n",
      "Rb_ppm: 99.75%\n",
      "Re_ppm: 100.00%\n",
      "S_pct: 100.00%\n",
      "Sb_ppm: 99.75%\n",
      "Sc_ppm: 97.28%\n",
      "Se_ppm: 100.00%\n",
      "Sn_ppm: 99.75%\n",
      "Sr_ppm: 99.75%\n",
      "Ta_ppm: 100.00%\n",
      "Tb_ppm: 100.00%\n",
      "Te_ppm: 99.75%\n",
      "Th_ppm: 99.75%\n",
      "Ti_pct: 97.78%\n",
      "Tl_ppm: 100.00%\n",
      "U_ppm: 99.75%\n",
      "V_ppm: 97.28%\n",
      "W_ppm: 99.75%\n",
      "Y_ppm: 97.28%\n",
      "Yb_ppm: 100.00%\n",
      "Zr_ppm: 97.28%\n"
     ]
    }
   ],
   "source": [
    "# 1. Identificar colunas com mais de 30% de valores problemáticos\n",
    "# Identify columns with more than 30% of LOD and NA values\n",
    "colunas_para_remover = []\n",
    "\n",
    "for col in colunas_com_dados:\n",
    "    porcentagem = contar_lod(df[col])\n",
    "    if porcentagem > 30:\n",
    "        # Armazena o nome da coluna e a porcentagem formatada\n",
    "        colunas_para_remover.append(f'{col}: {porcentagem:.2f}%')\n",
    "\n",
    "# 2. Remover as colunas do DataFrame\n",
    "# Extraímos apenas o nome (antes do ':') para poder dar o drop\n",
    "nomes_para_drop = [item.split(':')[0] for item in colunas_para_remover]\n",
    "df.drop(columns=nomes_para_drop, inplace=True)\n",
    "\n",
    "print(f'--- REMOVAL SUMMARY | RESUMO DE REMOÇÃO ---')\n",
    "if colunas_para_remover:\n",
    "    print(f'Removed {len(colunas_para_remover)} columns with >30% LOD/Nulls:')\n",
    "    for item in colunas_para_remover:\n",
    "        print(item)\n",
    "else:\n",
    "    print('No columns exceeded the 30% threshold.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01df42c5-09aa-4515-a93d-7bfef5f3cb2d",
   "metadata": {},
   "source": [
    "## 3.2. Replace LOD values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d234052-0fa0-46bf-9a6f-f4092d5172a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOD substitution completed | Substituição de LOD concluída.\n",
      "Detected Min LODs: {'Pb_ppm': 4.0, 'Zn_ppm': 200.0}\n",
      "Detected Max LODs: {}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Dicionários para armazenar os limites detectados\n",
    "# Dictionaries to store detected limits\n",
    "lod_min_dict = {}\n",
    "lod_max_dict = {}\n",
    "\n",
    "def tratar_geochem_lod(valor, col_name):\n",
    "    if pd.isna(valor) or not isinstance(valor, str):\n",
    "        return valor\n",
    "    \n",
    "    valor_ajustado = valor.replace(',', '.')\n",
    "    \n",
    "    # 2. Trata Limite de Detecção Inferior (ex: <0,5) -> LD/2\n",
    "    # 2. Handle Lower Detection Limit (e.g., <0.5) -> LOD/2\n",
    "    if '<' in valor_ajustado:\n",
    "        try:\n",
    "            num = float(re.sub(r'[^\\d.]', '', valor_ajustado))\n",
    "            # Armazena o valor do limite original (antes de dividir por 2)\n",
    "            # Stores the original limit value (before dividing by 2)\n",
    "            lod_min_dict[col_name] = num\n",
    "            return num / 2\n",
    "        except ValueError:\n",
    "            return valor\n",
    "            \n",
    "    # 3. Trata Limite de Detecção Máximo (ex: >500) -> Valor do Limite\n",
    "    # 3. Handle Maximum Detection Limit (e.g., >500) -> Limit Value\n",
    "    elif '>' in valor_ajustado:\n",
    "        try:\n",
    "            num = float(re.sub(r'[^\\d.]', '', valor_ajustado))\n",
    "            # Armazena o valor do limite máximo\n",
    "            # Stores the maximum limit value\n",
    "            lod_max_dict[col_name] = num\n",
    "            return num\n",
    "        except ValueError:\n",
    "            return valor\n",
    "            \n",
    "    try:\n",
    "        return float(valor_ajustado)\n",
    "    except ValueError:\n",
    "        return valor\n",
    "\n",
    "# Aplicando a função coluna por coluna para capturar o contexto (nome da coluna)\n",
    "# Applying the function column by column to capture context (column name)\n",
    "cols_analise = [col for col in df.columns if '_' in col]\n",
    "\n",
    "for col in cols_analise:\n",
    "    # Passamos o nome da coluna para a função via lambda\n",
    "    df[col] = df[col].apply(lambda x: tratar_geochem_lod(x, col))\n",
    "\n",
    "print('LOD substitution completed | Substituição de LOD concluída.')\n",
    "print(f'Detected Min LODs: {lod_min_dict}')\n",
    "print(f'Detected Max LODs: {lod_max_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73dafeeb-d0a7-463c-ac3e-1b43a21dbc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testes = ['10,5', '0,25', '1000,0', '5,2']\n",
    "# for t in testes:\n",
    "#     resultado = tratar_geochem_lod(t)\n",
    "#     print(f'Original: {t} -> Convertido: {resultado} (Tipo: {type(resultado)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6cf1bd-abf9-4ee3-bf60-43edeb774272",
   "metadata": {},
   "source": [
    "## 3.3. Negative mumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "487b8a94-934c-4eef-9c39-b5303228816c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NUMERO_DE_CAMPO', 'PROJETO_AMOSTRAGEM', 'PROJETO_PUBLICACAO', 'CENTRO_DE_CUSTO', 'CLASSE', 'NUMERO_DE_LABORATORIO', 'DUPLICATA', 'LATITUDE', 'LONGITUDE', 'LOTE', 'RA', 'DATA_DE_ANALISE', 'METODO', 'ABERTURA', 'LEITURA', 'LABORATORIO', 'JOB', 'ID_REGISTRO', 'ID_AMOSTRA', 'Cu_ppm', 'Fe_pct', 'Mn_ppm', 'Pb_ppm', 'Zn_ppm', 'OBSERVACAO']\n"
     ]
    }
   ],
   "source": [
    "# Show all collumns\n",
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e020030e-a2fa-4e68-b5be-e4e4d0cfa7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# element_list = ['Cu_ppm', 'Fe_pct', 'Mn_ppm', 'Pb_ppm', 'Zn_ppm']\n",
    "\n",
    "# for col in element_list:\n",
    "#     invalid = df.loc[pd.to_numeric(df[col], errors='coerce').isna() & df[col].notna(), col]\n",
    "#     if not invalid.empty:\n",
    "#         print(f'\\nColuna: {col}')\n",
    "#         print(invalid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae751f4d-ed8b-4066-b373-64e3e06bab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No negative values found. No rows were removed.\n"
     ]
    }
   ],
   "source": [
    "# 1. Seleciona apenas colunas dos elementos\n",
    "# 1. Select only element columns\n",
    "element_list = ['Cu_ppm', 'Fe_pct', 'Mn_ppm', 'Pb_ppm', 'Zn_ppm']\n",
    "\n",
    "# 2. Identificar as linhas com valores negativos antes da remoção\n",
    "# 2. Identify rows with negative values before removal\n",
    "rows_to_drop = df[(df[element_list] < 0).any(axis=1)].index\n",
    "\n",
    "# 3. Remover as linhas do DataFrame\n",
    "# 3. Drop the rows from the DataFrame\n",
    "if len(rows_to_drop) > 0:\n",
    "    df.drop(index=rows_to_drop, inplace=True)\n",
    "    print(f'--- REMOVAL SUMMARY | RESUMO DE REMOÇÃO ---')\n",
    "    print(f'Removed {len(rows_to_drop)} rows containing negative values.')\n",
    "    # Removed {len(rows_to_drop)} linhas contendo valores negativos.\n",
    "else:\n",
    "    print('No negative values found. No rows were removed.')\n",
    "    # Nenhum valor negativo encontrado. Nenhuma linha foi removida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157551c9-2c96-463c-8405-89080b4cf997",
   "metadata": {},
   "source": [
    "## 4. Mapping Elements and Measurement Units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7fbdd4-5cde-48b9-83f0-81bf7b3aef9b",
   "metadata": {},
   "source": [
    "O script percorre a `element_list` fornecida, dividindo cada string em Elemento e Unidade. Em seguida, faz um cruzamento com os LODs capturados para criar uma tabela de metadados abrangente para exportação. <br>\n",
    "<font color='gray'>The script iterates through the provided `element_list`, splitting each string into Element and Unit. It then cross-references this with the captured LODs to create a comprehensive metadata table for export.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d13dde4-bdd8-441a-bd72-435aa4709cb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- METADATA PREVIEW | PRÉVIA DOS METADADOS ---\n",
      "  Elemento Unidade LOD_Min LOD_Max Coluna_Original\n",
      "0       Cu     ppm     N/A     N/A          Cu_ppm\n",
      "1       Fe     pct     N/A     N/A          Fe_pct\n",
      "2       Mn     ppm     N/A     N/A          Mn_ppm\n",
      "3       Pb     ppm     4.0     N/A          Pb_ppm\n",
      "4       Zn     ppm   200.0     N/A          Zn_ppm\n"
     ]
    }
   ],
   "source": [
    "element_list = ['Cu_ppm', 'Fe_pct', 'Mn_ppm', 'Pb_ppm', 'Zn_ppm']\n",
    "\n",
    "# Lista para armazenar os metadados consolidados\n",
    "# List to store consolidated metadata\n",
    "metadados_quimicos = []\n",
    "\n",
    "for col in element_list:\n",
    "    # Divide a string pelo underline para separar Elemento de Unidade\n",
    "    # Split the string by underscore to separate Element from Unit\n",
    "    partes = col.split('_')\n",
    "    elemento = partes[0]\n",
    "    unidade = partes[1] if len(partes) >= 2 else 'N/A'\n",
    "    \n",
    "    # Recupera os limites de detecção dos dicionários capturados anteriormente\n",
    "    # Retrieve detection limits from the previously captured dictionaries\n",
    "    # Se não houver registro para a coluna, retorna 'N/A'\n",
    "    # If no record exists for the column, return 'N/A'\n",
    "    lod_min = lod_min_dict.get(col, 'N/A')\n",
    "    lod_max = lod_max_dict.get(col, 'N/A')\n",
    "    \n",
    "    # Adiciona as informações à lista\n",
    "    # Add information to the list\n",
    "    metadados_quimicos.append({\n",
    "        'Elemento': elemento, 'Unidade': unidade,\n",
    "        'LOD_Min': lod_min, 'LOD_Max': lod_max, 'Coluna_Original': col})\n",
    "\n",
    "# Cria o DataFrame de metadados\n",
    "# Create the metadata DataFrame\n",
    "df_metadados = pd.DataFrame(metadados_quimicos)\n",
    "\n",
    "# Visualização do resultado\n",
    "# View result\n",
    "print('--- METADATA PREVIEW | PRÉVIA DOS METADADOS ---')\n",
    "print(df_metadados.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d80d1d-d787-4e82-aa81-d1f13115c00e",
   "metadata": {},
   "source": [
    "# 5. Save data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d60d7-6e09-4ed1-b81e-cc31ed841b43",
   "metadata": {},
   "source": [
    "O processo de exportação final agora utiliza a `element_list` predefinida para construir o dicionário de metadados. Ele inclui apenas as colunas que passaram pelos filtros de qualidade anteriores, garantindo que o arquivo Excel reflita estritamente o conteúdo do banco de dados final. <br>\n",
    "<font color='gray'>The final export process now uses the predefined `element_list` to build the metadata dictionary. It only includes columns that passed previous quality filters, ensuring the Excel file strictly reflects the final database's contents.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cea0ba49-6d8d-4438-a6a8-59ac277bdf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de colunas para remover\n",
    "# List of columns to remove\n",
    "columns_to_remove = [\n",
    "    'NUMERO_DE_CAMPO', 'PROJETO_AMOSTRAGEM', 'PROJETO_PUBLICACAO', 'CENTRO_DE_CUSTO', 'CLASSE',\n",
    "    'NUMERO_DE_LABORATORIO', 'DUPLICATA', 'LATITUDE', 'LONGITUDE', 'LOTE', 'RA', 'DATA_DE_ANALISE',\n",
    "    'METODO', 'ABERTURA', 'LEITURA', 'LABORATORIO', 'JOB', 'OBSERVACAO']\n",
    "\n",
    "# Remove apenas as colunas que de fato existem no DataFrame atual\n",
    "# Remove only the columns that actually exist in the current DataFrame\n",
    "df.drop(columns=[col for col in columns_to_remove if col in df.columns], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "102d493c-861b-4a6b-bd55-d993aeb02550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID_REGISTRO', 'ID_AMOSTRA', 'Cu_ppm', 'Fe_pct', 'Mn_ppm', 'Pb_ppm', 'Zn_ppm']\n"
     ]
    }
   ],
   "source": [
    "# Show all collumns\n",
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b3a80d2-c0f2-46b5-b496-1e299a2a1115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel generated with complete Metadata! | Excel gerado com Metadados completos!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Lista de elementos alvo (definida pelo usuário)\n",
    "# 1. Target element list (user-defined)\n",
    "element_list = ['Cu_ppm', 'Fe_pct', 'Mn_ppm', 'Pb_ppm', 'Zn_ppm']\n",
    "\n",
    "# 2. Consolidar Elementos, Unidades e LODs em uma lista\n",
    "# 2. Consolidate Elements, Units, and LODs into a list\n",
    "metadados_quimicos = []\n",
    "\n",
    "# Filtramos a element_list para processar apenas o que restou no DataFrame atual\n",
    "# Filter element_list to process only what remains in the current DataFrame\n",
    "cols_presentes = [col for col in element_list if col in df.columns]\n",
    "\n",
    "for col in cols_presentes:\n",
    "    # Divide a string para separar Elemento e Unidade\n",
    "    # Split string to separate Element and Unit\n",
    "    partes = col.split('_')\n",
    "    elemento = partes[0]\n",
    "    unidade = partes[1] if len(partes) >= 2 else 'N/A'\n",
    "    \n",
    "    # Busca os valores nos dicionários capturados durante o tratamento de LOD\n",
    "    # Retrieve values from the dictionaries captured during LOD treatment\n",
    "    lod_min = lod_min_dict.get(col, 'N/A')\n",
    "    lod_max = lod_max_dict.get(col, 'N/A')\n",
    "    \n",
    "    metadados_quimicos.append({\n",
    "        'Elemento': elemento,\n",
    "        'Unidade': unidade,\n",
    "        'LOD_Min': lod_min,\n",
    "        'LOD_Max': lod_max,\n",
    "        'Coluna_Original': col\n",
    "    })\n",
    "\n",
    "# Criar DataFrame de metadados\n",
    "# Create metadata DataFrame\n",
    "df_metadados = pd.DataFrame(metadados_quimicos)\n",
    "\n",
    "# 3. Gerar o arquivo Excel com as abas atualizadas\n",
    "# 3. Generate the Excel file with updated sheets\n",
    "with pd.ExcelWriter('Data/' + file_name + '_PROC.xlsx', engine='xlsxwriter') as writer:\n",
    "    # Aba 1: Dados Filtrados e Convertidos (Dataset principal)\n",
    "    # Sheet 1: Filtered and Converted Data (Main dataset)\n",
    "    df.to_excel(writer, sheet_name='Dados_Filtrados', index=False)\n",
    "    \n",
    "    # Aba 2: Dicionário de Metadados (Elementos, Unidades e LODs)\n",
    "    # Sheet 2: Metadata Dictionary (Elements, Units, and LODs)\n",
    "    df_metadados.to_excel(writer, sheet_name='Dicionario_Metadados', index=False)\n",
    "    \n",
    "    # Aba 3: Registro de Duplicatas (se o objeto existir no ambiente)\n",
    "    # Sheet 3: Duplicate Records (if object exists in environment)\n",
    "    if 'df_duplicata' in locals():\n",
    "        df_duplicata.to_excel(writer, sheet_name='Registro_Duplicatas', index=False)\n",
    "\n",
    "print('Excel generated with complete Metadata! | Excel gerado com Metadados completos!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
