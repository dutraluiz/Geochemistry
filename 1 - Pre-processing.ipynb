{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2455dc39-af63-4198-827e-2c6929bf8f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# desabilitar avisos\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e581b6-599c-483d-a53a-50e1a9596f9e",
   "metadata": {},
   "source": [
    "# 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f98dce-1053-4e4f-ad19-93f4ea856345",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'SEDIMENTO DE CORRENTE' # será usado para salvar o arquivo processado\n",
    "df = pd.read_excel('Data/' + file_name + '.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "545216a1-cd0e-4a84-9792-2d21a716bfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROJETO_AMOSTRAGEM', 'PROJETO_PUBLICACAO', 'CENTRO_DE_CUSTO', 'CLASSE', 'NUMERO_DE_CAMPO', 'NUMERO_DE_LABORATORIO', 'DUPLICATA', 'LATITUDE', 'LONGITUDE', 'LOTE', 'RA', 'DATA_DE_ANALISE', 'METODO', 'ABERTURA', 'LEITURA', 'LABORATORIO', 'JOB', 'Ag_ppb', 'Ag_ppm', 'Al_pct', 'Al2O3_pct', 'As_ppm', 'Au_ppb', 'Au1_ppb', 'Au2_ppb', 'Au_ppm', 'B_ppm', 'Ba_ppm', 'BaO_pct', 'Be_ppm', 'Bi_ppm', 'C_organico_pct', 'C_elementar_pct', 'Ca_pct', 'CaO_pct', 'Cd_ppm', 'Ce_ppm', 'Cl_ppm', 'Co_ppm', 'CO3_pct', 'Cr_pct', 'Cr_ppm', 'Cr2O3_pct', 'Cs_ppm', 'Cu_ppm', 'Dy_ppm', 'Er_ppm', 'Eu_ppm', 'F_ppm', 'Fe_pct', 'Fe_ppm', 'Fe2O3_pct', 'FeO_pct', 'Ga_ppm', 'Gd_ppm', 'Ge_ppm', 'Hf_ppm', 'Hg_ppb', 'Hg_ppm', 'Ho_ppm', 'In_ppm', 'K_pct', 'K2O_pct', 'La_ppm', 'Li_ppm', 'Lu_ppm', 'Mg_pct', 'MgO_pct', 'Mn_pct', 'Mn_ppm', 'MnO_pct', 'Mo_ppm', 'Na_pct', 'Na2O_pct', 'Nb_ppm', 'Nb2O5_pct', 'Nd_ppm', 'Ni_pct', 'Ni_ppm', 'P_pct', 'P_ppm', 'P2O5_pct', 'Pb_ppb', 'Pb_ppm', 'Pd_ppm', 'Pd_ppb', 'PF_pct', 'Pr_ppm', 'Pt_ppb', 'Pt_ppm', 'Rb_ppm', 'Re_ppb', 'Re_ppm', 'Rh_ppb', 'S_pct', 'Sb_ppm', 'Sc_ppm', 'Se_ppm', 'SiO2_pct', 'Sm_ppm', 'Sn_ppm', 'Sr_ppm', 'Soma_pct', 'Ta_ppm', 'Tb_ppm', 'Te_ppm', 'Th_ppm', 'Ti_pct', 'Ti_ppm', 'TiO2_pct', 'Tl_ppm', 'Tm_ppm', 'U_ppm', 'V_ppm', 'W_ppm', 'Y_ppm', 'Yb_ppm', 'Zn_ppm', 'Zr_ppm', 'OBSERVACAO']\n"
     ]
    }
   ],
   "source": [
    "# Show all collumns\n",
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf86f20c-eefe-4fe4-b91a-21c45f21209a",
   "metadata": {},
   "source": [
    "# 2. Organizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d24768-cefa-4533-937a-012d391ae9b2",
   "metadata": {},
   "source": [
    "## 2.1. ID columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0321ec-d300-4e44-a774-4e54c0561287",
   "metadata": {},
   "source": [
    "As colunas `ID_AMOSTRA` e `ID_REGISTRO` são colocadas após a coluna `JOB`. Encontre o índice da coluna `JOB` e adicione 1 e 2, respectivamente. <br>\n",
    "<font color='gray'>The `ID_AMOSTRA` and `ID_REGISTRO` columns are placed after the `JOB` column. Find the index of the `JOB` column and add 1 and 2, respectively.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412a01a8-b0e5-43dc-9b47-a610e6dc527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reference position\n",
    "base_pos = df.columns.get_loc('JOB')\n",
    "\n",
    "# Insert ID_AMOSTRA at JOB + 1\n",
    "df.insert(base_pos + 1, 'ID_AMOSTRA', df['NUMERO_DE_CAMPO'])\n",
    "\n",
    "# Insert ID_REGISTRO at JOB + 2\n",
    "df.insert(base_pos + 1, 'ID_REGISTRO', df['NUMERO_DE_CAMPO'] + '_' + df['METODO'] + '_' + df['JOB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b55ec8-8c35-4640-b6c3-15fbe85de28b",
   "metadata": {},
   "source": [
    "## 2.2. Remove duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c3cc0-45bc-4fd8-9bff-d3471f9e2364",
   "metadata": {},
   "source": [
    "### Filtering by DUPLICATA column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b13096a9-1359-4e57-9a96-5ab387740e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Sim'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DUPLICATA'].unique() #Verificar como são classificadas as duplicatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed02e78-2c76-43fc-b7be-1b118671499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra somente os dados que a 'DUPLICATA' não é 'Sim'\n",
    "# Filtering the dataframe to keep only rows where 'DUPLICATA' is not 'Sim'\n",
    "df_duplicata = df[(df['DUPLICATA'] == 'Sim')]\n",
    "df = df[~(df['DUPLICATA'] == 'Sim')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856839c4-1aeb-4637-ac6b-3eda78d60e2e",
   "metadata": {},
   "source": [
    "### Filterin by duplicate ID_AMOSTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e170706-39da-48b8-94da-0061fc2391b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: No duplicate ID_AMOSTRA found.\n"
     ]
    }
   ],
   "source": [
    "# Identify rows with duplicate ID_AMOSTRA\n",
    "duplicates_count = df['ID_AMOSTRA'].duplicated().sum()\n",
    "\n",
    "if duplicates_count > 0:\n",
    "    print(f'Warning: {duplicates_count} duplicate IDs found!')\n",
    "    # Show the duplicated rows for inspection\n",
    "    df_duplicates = df[df['ID_AMOSTRA'].duplicated(keep=False)]\n",
    "    print(df_duplicates.sort_values(by='ID_AMOSTRA'))\n",
    "else:\n",
    "    print('Success: No duplicate ID_AMOSTRA found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d8fd17-15ec-4610-a14f-0c1eaed88613",
   "metadata": {},
   "source": [
    "# 3. Limit of detection (LOD), NA and zero values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db0fa48-bd3b-4204-a64c-46e0783a93d7",
   "metadata": {},
   "source": [
    "## 3.1. Filtering data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8053e441-47bb-4cbf-82ee-3eafae100e40",
   "metadata": {},
   "source": [
    "Identifica e quantifica a presença de valores relacionados a Limites de Detecção (LOD), zeros e nulos. Os resultados são divididos em duas saídas: uma lista de colunas totalmente vazias e uma tabela mostrando a porcentagem de valores 'não ideais' por elemento <br>\n",
    "<font color='gray'>Identify and quantify the presence of values related to Limits of Detection (LOD), zeros, and nulls. The results are split into two outputs: a list of entirely empty columns and a table showing the percentage of 'non-ideal' values per element.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b337ff1-5275-485a-b922-dc95884f8ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EMPTY COLUMNS | COLUNAS VAZIAS ---\n",
      "['Ag_ppb', 'Al2O3_pct', 'Au_ppb', 'Au1_ppb', 'Au2_ppb', 'BaO_pct', 'C_organico_pct', 'C_elementar_pct', 'CaO_pct', 'Cl_ppm', 'CO3_pct', 'Cr_pct', 'Cr2O3_pct', 'Dy_ppm', 'Er_ppm', 'Eu_ppm', 'F_ppm', 'Fe_ppm', 'Fe2O3_pct', 'FeO_pct', 'Gd_ppm', 'Hg_ppb', 'Ho_ppm', 'K2O_pct', 'MgO_pct', 'Mn_pct', 'MnO_pct', 'Na2O_pct', 'Nb2O5_pct', 'Nd_ppm', 'Ni_pct', 'P_pct', 'P2O5_pct', 'Pb_ppb', 'Pd_ppm', 'Pd_ppb', 'PF_pct', 'Pr_ppm', 'Pt_ppb', 'Pt_ppm', 'Re_ppb', 'Rh_ppb', 'SiO2_pct', 'Sm_ppm', 'Soma_pct', 'Ti_ppm', 'TiO2_pct', 'Tm_ppm']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identificar colunas numéricas (elementos) e colunas totalmente vazias\n",
    "# Identify empty columns\n",
    "cols_elementos = [col for col in df.columns if '_' in col]\n",
    "colunas_vazias = [col for col in cols_elementos if df[col].isnull().all()]\n",
    "colunas_com_dados = [col for col in cols_elementos if col not in colunas_vazias]\n",
    "\n",
    "# Saída 1: Lista de colunas vazias\n",
    "print('--- EMPTY COLUMNS | COLUNAS VAZIAS ---')\n",
    "if colunas_vazias:\n",
    "    print(colunas_vazias)\n",
    "else:\n",
    "    print('No entirely empty columns found.')\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e8837ea-57da-43ce-a063-f19dc2f46324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 48 empty columns.\n"
     ]
    }
   ],
   "source": [
    "# Remover colunas vazias\n",
    "# Remove empty columns\n",
    "\n",
    "df.drop(columns=colunas_vazias, inplace=True)\n",
    "\n",
    "print(f'Removed {len(colunas_vazias)} empty columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31d5d84d-7083-4e6c-9400-a3f152e749e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LOD & NULL SUMMARY (%) | RESUMO DE LOD E NULOS (%) ---\n",
      "       LOD/Null %\n",
      "Ag_ppm    100.00%\n",
      "Al_pct      0.56%\n",
      "As_ppm      8.10%\n",
      "Au_ppm    100.00%\n",
      "B_ppm     100.00%\n",
      "Bi_ppm      0.28%\n",
      "Ca_pct     21.79%\n",
      "Cd_ppm     18.16%\n",
      "Fe_pct      0.56%\n",
      "Ge_ppm     99.44%\n",
      "Hf_ppm     31.56%\n",
      "Hg_ppm    100.00%\n",
      "In_ppm     14.25%\n",
      "K_pct       0.84%\n",
      "Li_ppm      1.12%\n",
      "Lu_ppm     27.65%\n",
      "Mg_pct     16.48%\n",
      "Mo_ppm      2.23%\n",
      "Na_pct     91.06%\n",
      "Nb_ppm      9.22%\n",
      "Ni_ppm    100.00%\n",
      "P_ppm     100.00%\n",
      "Rb_ppm     70.67%\n",
      "Re_ppm    100.00%\n",
      "S_pct      26.54%\n",
      "Sb_ppm     68.16%\n",
      "Sc_ppm      5.31%\n",
      "Se_ppm     27.65%\n",
      "Sn_ppm     71.79%\n",
      "Ta_ppm      5.03%\n",
      "Tb_ppm    100.00%\n",
      "Th_ppm     57.26%\n",
      "Ti_pct    100.00%\n",
      "Tl_ppm    100.00%\n",
      "V_ppm      65.08%\n",
      "W_ppm      25.42%\n",
      "Yb_ppm     94.97%\n",
      "Zr_ppm      0.28%\n"
     ]
    }
   ],
   "source": [
    "# Função para identificar o que é 'LOD' ou dado problemático\n",
    "# Identify LOD value\n",
    "def contar_lod(series):\n",
    "    # Converte para string para buscar símbolos, mas mantém análise de nulos/zeros\n",
    "    total = len(series)\n",
    "    # Contagem de nulos, zeros e strings com < ou >\n",
    "    mascara_lod = (\n",
    "        series.astype(str).str.contains('<|>') | \n",
    "        (series == 0) | \n",
    "        series.isna()\n",
    "    )\n",
    "    soma = mascara_lod.sum()\n",
    "    return (soma / total) * 100 if soma > 0 else 0\n",
    "\n",
    "# Gerar resultados\n",
    "resultados = {}\n",
    "for col in colunas_com_dados:\n",
    "    porcentagem = contar_lod(df[col])\n",
    "    if porcentagem > 0:\n",
    "        resultados[col] = f'{porcentagem:.2f}%'\n",
    "\n",
    "print('--- LOD & NULL SUMMARY (%) | RESUMO DE LOD E NULOS (%) ---')\n",
    "if resultados:\n",
    "    df_resumo = pd.DataFrame.from_dict(resultados, orient='index', columns=['LOD/Null %'])\n",
    "    print(df_resumo)\n",
    "else:\n",
    "    print('No LOD or null values detected in data-containing columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f57302ab-9cc2-4e64-a990-b720472b39c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- REMOVAL SUMMARY | RESUMO DE REMOÇÃO ---\n",
      "Removed 19 columns with >30% LOD/Nulls:\n",
      "Ag_ppm: 100.00%\n",
      "Au_ppm: 100.00%\n",
      "B_ppm: 100.00%\n",
      "Ge_ppm: 99.44%\n",
      "Hf_ppm: 31.56%\n",
      "Hg_ppm: 100.00%\n",
      "Na_pct: 91.06%\n",
      "Ni_ppm: 100.00%\n",
      "P_ppm: 100.00%\n",
      "Rb_ppm: 70.67%\n",
      "Re_ppm: 100.00%\n",
      "Sb_ppm: 68.16%\n",
      "Sn_ppm: 71.79%\n",
      "Tb_ppm: 100.00%\n",
      "Th_ppm: 57.26%\n",
      "Ti_pct: 100.00%\n",
      "Tl_ppm: 100.00%\n",
      "V_ppm: 65.08%\n",
      "Yb_ppm: 94.97%\n"
     ]
    }
   ],
   "source": [
    "# 1. Identificar colunas com mais de 30% de valores problemáticos\n",
    "# Identify columns with more than 30% of LOD and NA values\n",
    "colunas_para_remover = []\n",
    "\n",
    "for col in colunas_com_dados:\n",
    "    porcentagem = contar_lod(df[col])\n",
    "    if porcentagem > 30:\n",
    "        # Armazena o nome da coluna e a porcentagem formatada\n",
    "        colunas_para_remover.append(f'{col}: {porcentagem:.2f}%')\n",
    "\n",
    "# 2. Remover as colunas do DataFrame\n",
    "# Extraímos apenas o nome (antes do ':') para poder dar o drop\n",
    "nomes_para_drop = [item.split(':')[0] for item in colunas_para_remover]\n",
    "df.drop(columns=nomes_para_drop, inplace=True)\n",
    "\n",
    "print(f'--- REMOVAL SUMMARY | RESUMO DE REMOÇÃO ---')\n",
    "if colunas_para_remover:\n",
    "    print(f'Removed {len(colunas_para_remover)} columns with >30% LOD/Nulls:')\n",
    "    for item in colunas_para_remover:\n",
    "        print(item)\n",
    "else:\n",
    "    print('No columns exceeded the 30% threshold.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b3ee28-895c-41d8-9ccb-0cb90d723e6b",
   "metadata": {},
   "source": [
    "## 3.2. Replace LOD values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15355e10-2fc8-4bd6-98a4-85b3334315ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOD substitution completed | Substituição de LOD concluída.\n",
      "Detected Min LODs: {'Al_pct': 0.01, 'As_ppm': 1.0, 'Bi_ppm': 0.02, 'Ca_pct': 0.01, 'Cd_ppm': 0.01, 'Fe_pct': 0.01, 'In_ppm': 0.02, 'K_pct': 0.01, 'Li_ppm': 1.0, 'Lu_ppm': 0.01, 'Mg_pct': 0.01, 'Mo_ppm': 0.05, 'Nb_ppm': 0.05, 'S_pct': 0.01, 'Sc_ppm': 0.1, 'Se_ppm': 1.0, 'Ta_ppm': 0.05, 'W_ppm': 0.1, 'Zr_ppm': 0.5}\n",
      "Detected Max LODs: {}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Dicionários para armazenar os limites detectados\n",
    "# Dictionaries to store detected limits\n",
    "lod_min_dict = {}\n",
    "lod_max_dict = {}\n",
    "\n",
    "def tratar_geochem_lod(valor, col_name):\n",
    "    if pd.isna(valor) or not isinstance(valor, str):\n",
    "        return valor\n",
    "    \n",
    "    valor_ajustado = valor.replace(',', '.')\n",
    "    \n",
    "    # 2. Trata Limite de Detecção Inferior (ex: <0,5) -> LD/2\n",
    "    # 2. Handle Lower Detection Limit (e.g., <0.5) -> LOD/2\n",
    "    if '<' in valor_ajustado:\n",
    "        try:\n",
    "            num = float(re.sub(r'[^\\d.]', '', valor_ajustado))\n",
    "            # Armazena o valor do limite original (antes de dividir por 2)\n",
    "            # Stores the original limit value (before dividing by 2)\n",
    "            lod_min_dict[col_name] = num\n",
    "            return num / 2\n",
    "        except ValueError:\n",
    "            return valor\n",
    "            \n",
    "    # 3. Trata Limite de Detecção Máximo (ex: >500) -> Valor do Limite\n",
    "    # 3. Handle Maximum Detection Limit (e.g., >500) -> Limit Value\n",
    "    elif '>' in valor_ajustado:\n",
    "        try:\n",
    "            num = float(re.sub(r'[^\\d.]', '', valor_ajustado))\n",
    "            # Armazena o valor do limite máximo\n",
    "            # Stores the maximum limit value\n",
    "            lod_max_dict[col_name] = num\n",
    "            return num\n",
    "        except ValueError:\n",
    "            return valor\n",
    "            \n",
    "    try:\n",
    "        return float(valor_ajustado)\n",
    "    except ValueError:\n",
    "        return valor\n",
    "\n",
    "# Aplicando a função coluna por coluna para capturar o contexto (nome da coluna)\n",
    "# Applying the function column by column to capture context (column name)\n",
    "cols_analise = [col for col in df.columns if '_' in col]\n",
    "\n",
    "for col in cols_analise:\n",
    "    # Passamos o nome da coluna para a função via lambda\n",
    "    df[col] = df[col].apply(lambda x: tratar_geochem_lod(x, col))\n",
    "\n",
    "print('LOD substitution completed | Substituição de LOD concluída.')\n",
    "print(f'Detected Min LODs: {lod_min_dict}')\n",
    "print(f'Detected Max LODs: {lod_max_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b35a347-90dc-4ad3-ae46-f870356a503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testes = ['10,5', '0,25', '1000,0', '5,2']\n",
    "# for t in testes:\n",
    "#     resultado = tratar_geochem_lod(t)\n",
    "#     print(f'Original: {t} -> Convertido: {resultado} (Tipo: {type(resultado)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2284cd-1ef9-4ca6-920b-b44f067fca46",
   "metadata": {},
   "source": [
    "## 3.3. Negative mumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82323f1e-517c-4a22-969e-470ea2399f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROJETO_AMOSTRAGEM', 'PROJETO_PUBLICACAO', 'CENTRO_DE_CUSTO', 'CLASSE', 'NUMERO_DE_CAMPO', 'NUMERO_DE_LABORATORIO', 'DUPLICATA', 'LATITUDE', 'LONGITUDE', 'LOTE', 'RA', 'DATA_DE_ANALISE', 'METODO', 'ABERTURA', 'LEITURA', 'LABORATORIO', 'JOB', 'ID_REGISTRO', 'ID_AMOSTRA', 'Al_pct', 'As_ppm', 'Ba_ppm', 'Be_ppm', 'Bi_ppm', 'Ca_pct', 'Cd_ppm', 'Ce_ppm', 'Co_ppm', 'Cr_ppm', 'Cs_ppm', 'Cu_ppm', 'Fe_pct', 'Ga_ppm', 'In_ppm', 'K_pct', 'La_ppm', 'Li_ppm', 'Lu_ppm', 'Mg_pct', 'Mn_ppm', 'Mo_ppm', 'Nb_ppm', 'Pb_ppm', 'S_pct', 'Sc_ppm', 'Se_ppm', 'Sr_ppm', 'Ta_ppm', 'Te_ppm', 'U_ppm', 'W_ppm', 'Y_ppm', 'Zn_ppm', 'Zr_ppm', 'OBSERVACAO']\n"
     ]
    }
   ],
   "source": [
    "# Show all collumns\n",
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ebf5c66-c8cf-407f-af55-31eb6efa46d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No negative values found. No rows were removed.\n"
     ]
    }
   ],
   "source": [
    "# 1. Seleciona apenas colunas dos elementos\n",
    "# 1. Select only element columns\n",
    "element_list = ['Al_pct', 'As_ppm', 'Ba_ppm', 'Be_ppm', 'Bi_ppm', 'Ca_pct', 'Cd_ppm', 'Ce_ppm', 'Co_ppm', 'Cr_ppm', 'Cs_ppm', 'Cu_ppm',\n",
    "                'Fe_pct', 'Ga_ppm', 'In_ppm', 'K_pct', 'La_ppm', 'Li_ppm', 'Lu_ppm', 'Mg_pct', 'Mn_ppm', 'Mo_ppm', 'Nb_ppm', 'Pb_ppm', 'S_pct',\n",
    "                'Sc_ppm', 'Se_ppm', 'Sr_ppm', 'Ta_ppm', 'Te_ppm', 'U_ppm', 'W_ppm', 'Y_ppm', 'Zn_ppm', 'Zr_ppm']\n",
    "\n",
    "# 2. Identificar as linhas com valores negativos antes da remoção\n",
    "# 2. Identify rows with negative values before removal\n",
    "rows_to_drop = df[(df[element_list] < 0).any(axis=1)].index\n",
    "\n",
    "# 3. Remover as linhas do DataFrame\n",
    "# 3. Drop the rows from the DataFrame\n",
    "if len(rows_to_drop) > 0:\n",
    "    df.drop(index=rows_to_drop, inplace=True)\n",
    "    print(f'--- REMOVAL SUMMARY | RESUMO DE REMOÇÃO ---')\n",
    "    print(f'Removed {len(rows_to_drop)} rows containing negative values.')\n",
    "    # Removed {len(rows_to_drop)} linhas contendo valores negativos.\n",
    "else:\n",
    "    print('No negative values found. No rows were removed.')\n",
    "    # Nenhum valor negativo encontrado. Nenhuma linha foi removida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f663834-009c-4092-97e7-4fd8a6f06080",
   "metadata": {},
   "source": [
    "## 4. Mapping Elements and Measurement Units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0ab47-9d4f-4ec1-96ab-4c29afe2a8ef",
   "metadata": {},
   "source": [
    "O script percorre a `element_list` fornecida, dividindo cada string em Elemento e Unidade. Em seguida, faz um cruzamento com os LODs capturados para criar uma tabela de metadados abrangente para exportação. <br>\n",
    "<font color='gray'>The script iterates through the provided `element_list`, splitting each string into Element and Unit. It then cross-references this with the captured LODs to create a comprehensive metadata table for export.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d24d3f1b-b6d2-49d4-bf04-3e17e216497b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- METADATA PREVIEW | PRÉVIA DOS METADADOS ---\n",
      "  Elemento Unidade LOD_Min LOD_Max Coluna_Original\n",
      "0       Al     pct    0.01     N/A          Al_pct\n",
      "1       As     ppm     1.0     N/A          As_ppm\n",
      "2       Ba     ppm     N/A     N/A          Ba_ppm\n",
      "3       Be     ppm     N/A     N/A          Be_ppm\n",
      "4       Bi     ppm    0.02     N/A          Bi_ppm\n",
      "\n",
      "Excel file updated with element_list metadata! | Arquivo Excel atualizado com os metadados da element_list!\n"
     ]
    }
   ],
   "source": [
    "element_list = [\n",
    "    'Al_pct', 'As_ppm', 'Ba_ppm', 'Be_ppm', 'Bi_ppm', 'Ca_pct', 'Cd_ppm', 'Ce_ppm', 'Co_ppm', 'Cr_ppm', 'Cs_ppm', 'Cu_ppm',\n",
    "    'Fe_pct', 'Ga_ppm', 'In_ppm', 'K_pct', 'La_ppm', 'Li_ppm', 'Lu_ppm', 'Mg_pct', 'Mn_ppm', 'Mo_ppm', 'Nb_ppm', 'Pb_ppm', 'S_pct',\n",
    "    'Sc_ppm', 'Se_ppm', 'Sr_ppm', 'Ta_ppm', 'Te_ppm', 'U_ppm', 'W_ppm', 'Y_ppm', 'Zn_ppm', 'Zr_ppm']\n",
    "\n",
    "# Lista para armazenar os metadados consolidados\n",
    "# List to store consolidated metadata\n",
    "metadados_quimicos = []\n",
    "\n",
    "for col in element_list:\n",
    "    # Divide a string pelo underline para separar Elemento de Unidade\n",
    "    # Split the string by underscore to separate Element from Unit\n",
    "    partes = col.split('_')\n",
    "    elemento = partes[0]\n",
    "    unidade = partes[1] if len(partes) >= 2 else 'N/A'\n",
    "    \n",
    "    # Recupera os limites de detecção dos dicionários capturados anteriormente\n",
    "    # Retrieve detection limits from the previously captured dictionaries\n",
    "    # Se não houver registro para a coluna, retorna 'N/A'\n",
    "    # If no record exists for the column, return 'N/A'\n",
    "    lod_min = lod_min_dict.get(col, 'N/A')\n",
    "    lod_max = lod_max_dict.get(col, 'N/A')\n",
    "    \n",
    "    # Adiciona as informações à lista\n",
    "    # Add information to the list\n",
    "    metadados_quimicos.append({\n",
    "        'Elemento': elemento, 'Unidade': unidade,\n",
    "        'LOD_Min': lod_min, 'LOD_Max': lod_max, 'Coluna_Original': col})\n",
    "\n",
    "# Cria o DataFrame de metadados\n",
    "# Create the metadata DataFrame\n",
    "df_metadados = pd.DataFrame(metadados_quimicos)\n",
    "\n",
    "# Visualização do resultado\n",
    "# View result\n",
    "print('--- METADATA PREVIEW | PRÉVIA DOS METADADOS ---')\n",
    "print(df_metadados.head())\n",
    "\n",
    "# Exportação para Excel com múltiplas abas\n",
    "# Export to Excel with multiple sheets\n",
    "with pd.ExcelWriter('Banco_Dados_Geoquimico.xlsx', engine='xlsxwriter') as writer:\n",
    "    # Aba de Dados Filtrados (seu DataFrame principal limpo)\n",
    "    # Sheet for Filtered Data (your clean main DataFrame)\n",
    "    df.to_excel(writer, sheet_name='Dados_Filtrados', index=False)\n",
    "    \n",
    "    # Aba de Metadados baseada na element_list\n",
    "    # Metadata sheet based on element_list\n",
    "    df_metadados.to_excel(writer, sheet_name='Dicionario_Metadados', index=False)\n",
    "\n",
    "print('\\nExcel file updated with element_list metadata! | Arquivo Excel atualizado com os metadados da element_list!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e28a76-6e07-43e3-b196-5b0d31ec5e80",
   "metadata": {},
   "source": [
    "# 5. Save data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a0400-9699-447d-bc14-fdd8df0b8b6e",
   "metadata": {},
   "source": [
    "O processo de exportação final agora utiliza a `element_list` predefinida para construir o dicionário de metadados. Ele inclui apenas as colunas que passaram pelos filtros de qualidade anteriores, garantindo que o arquivo Excel reflita estritamente o conteúdo do banco de dados final. <br>\n",
    "<font color='gray'>The final export process now uses the predefined `element_list` to build the metadata dictionary. It only includes columns that passed previous quality filters, ensuring the Excel file strictly reflects the final database's contents.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edbba118-dd42-4f65-a962-a466967ba54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de colunas para remover\n",
    "# List of columns to remove\n",
    "columns_to_remove = [\n",
    "    'PROJETO_AMOSTRAGEM', 'PROJETO_PUBLICACAO', 'CENTRO_DE_CUSTO', 'CLASSE', \n",
    "    'NUMERO_DE_CAMPO', 'NUMERO_DE_LABORATORIO', 'DUPLICATA', 'LOTE', 'RA', \n",
    "    'DATA_DE_ANALISE', 'METODO', 'ABERTURA', 'LEITURA', 'LABORATORIO', 'JOB', 'OBSERVACAO']\n",
    "\n",
    "# Remove apenas as colunas que de fato existem no DataFrame atual\n",
    "# Remove only the columns that actually exist in the current DataFrame\n",
    "df.drop(columns=[col for col in columns_to_remove if col in df.columns], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "274cf963-06a1-4fd9-8019-1647b99cae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LATITUDE', 'LONGITUDE', 'ID_REGISTRO', 'ID_AMOSTRA', 'Al_pct', 'As_ppm', 'Ba_ppm', 'Be_ppm', 'Bi_ppm', 'Ca_pct', 'Cd_ppm', 'Ce_ppm', 'Co_ppm', 'Cr_ppm', 'Cs_ppm', 'Cu_ppm', 'Fe_pct', 'Ga_ppm', 'In_ppm', 'K_pct', 'La_ppm', 'Li_ppm', 'Lu_ppm', 'Mg_pct', 'Mn_ppm', 'Mo_ppm', 'Nb_ppm', 'Pb_ppm', 'S_pct', 'Sc_ppm', 'Se_ppm', 'Sr_ppm', 'Ta_ppm', 'Te_ppm', 'U_ppm', 'W_ppm', 'Y_ppm', 'Zn_ppm', 'Zr_ppm', 'OBSERVACAO']\n"
     ]
    }
   ],
   "source": [
    "# Show all collumns\n",
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "260474f9-8cf7-44ca-b703-29cfae5e60d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel generated with complete Metadata! | Excel gerado com Metadados completos!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Lista de elementos alvo (definida pelo usuário)\n",
    "# 1. Target element list (user-defined)\n",
    "element_list = [\n",
    "    'Al_pct', 'As_ppm', 'Ba_ppm', 'Be_ppm', 'Bi_ppm', 'Ca_pct', 'Cd_ppm', 'Ce_ppm', 'Co_ppm', 'Cr_ppm', 'Cs_ppm', 'Cu_ppm',\n",
    "    'Fe_pct', 'Ga_ppm', 'In_ppm', 'K_pct', 'La_ppm', 'Li_ppm', 'Lu_ppm', 'Mg_pct', 'Mn_ppm', 'Mo_ppm', 'Nb_ppm', 'Pb_ppm', 'S_pct',\n",
    "    'Sc_ppm', 'Se_ppm', 'Sr_ppm', 'Ta_ppm', 'Te_ppm', 'U_ppm', 'W_ppm', 'Y_ppm', 'Zn_ppm', 'Zr_ppm'\n",
    "]\n",
    "\n",
    "# 2. Consolidar Elementos, Unidades e LODs em uma lista\n",
    "# 2. Consolidate Elements, Units, and LODs into a list\n",
    "metadados_quimicos = []\n",
    "\n",
    "# Filtramos a element_list para processar apenas o que restou no DataFrame atual\n",
    "# Filter element_list to process only what remains in the current DataFrame\n",
    "cols_presentes = [col for col in element_list if col in df.columns]\n",
    "\n",
    "for col in cols_presentes:\n",
    "    # Divide a string para separar Elemento e Unidade\n",
    "    # Split string to separate Element and Unit\n",
    "    partes = col.split('_')\n",
    "    elemento = partes[0]\n",
    "    unidade = partes[1] if len(partes) >= 2 else 'N/A'\n",
    "    \n",
    "    # Busca os valores nos dicionários capturados durante o tratamento de LOD\n",
    "    # Retrieve values from the dictionaries captured during LOD treatment\n",
    "    lod_min = lod_min_dict.get(col, 'N/A')\n",
    "    lod_max = lod_max_dict.get(col, 'N/A')\n",
    "    \n",
    "    metadados_quimicos.append({\n",
    "        'Elemento': elemento,\n",
    "        'Unidade': unidade,\n",
    "        'LOD_Min': lod_min,\n",
    "        'LOD_Max': lod_max,\n",
    "        'Coluna_Original': col\n",
    "    })\n",
    "\n",
    "# Criar DataFrame de metadados\n",
    "# Create metadata DataFrame\n",
    "df_metadados = pd.DataFrame(metadados_quimicos)\n",
    "\n",
    "# 3. Gerar o arquivo Excel com as abas atualizadas\n",
    "# 3. Generate the Excel file with updated sheets\n",
    "with pd.ExcelWriter('Data/' + file_name + '_PROC.xlsx', engine='xlsxwriter') as writer:\n",
    "    # Aba 1: Dados Filtrados e Convertidos (Dataset principal)\n",
    "    # Sheet 1: Filtered and Converted Data (Main dataset)\n",
    "    df.to_excel(writer, sheet_name='Dados_Filtrados', index=False)\n",
    "    \n",
    "    # Aba 2: Dicionário de Metadados (Elementos, Unidades e LODs)\n",
    "    # Sheet 2: Metadata Dictionary (Elements, Units, and LODs)\n",
    "    df_metadados.to_excel(writer, sheet_name='Dicionario_Metadados', index=False)\n",
    "    \n",
    "    # Aba 3: Registro de Duplicatas (se o objeto existir no ambiente)\n",
    "    # Sheet 3: Duplicate Records (if object exists in environment)\n",
    "    if 'df_duplicata' in locals():\n",
    "        df_duplicata.to_excel(writer, sheet_name='Registro_Duplicatas', index=False)\n",
    "\n",
    "print('Excel generated with complete Metadata! | Excel gerado com Metadados completos!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d432a54-9061-48ee-93d2-46df8d1f6a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
